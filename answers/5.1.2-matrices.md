#### 5.1.2 Matrices

_If some characters seem to be missing, it's because MathJax is not loaded correctly. Refreshing the page should fix it._

1. [E] Why do we say that matrices are linear transformations?
	
	*Answer:* Matrices are said to be linear transformations because they map vectors in a linear manner. A linear transformation is a function that maps vectors to vectors and satisfies the following two properties:

	Additivity: If $v_1$ and $v_2$ are vectors then $T(v_1 + v_2) = T(v_1) + T(v_2)$.

	Homogeneity: If $v$ is a vector and $c$ is a scalar, then $T(cv) = cT(v)$.

	A matrix can be used to represent a linear transformation by defining the action of the transformation on the columns of the matrix. The matrix-vector product $y = Ax$ can be thought of as transforming the vector $x$ into a new vector $y$ according to the linear transformation represented by the matrix $A$.

	The properties of additivity and homogeneity are preserved under the matrix-vector product, so matrices are a convenient and powerful way of representing linear transformations.

2. [E] What’s the inverse of a matrix? Do all matrices have an inverse? Is the inverse of a matrix always unique?
	
	*Answer:* 
	The inverse of a matrix is a matrix that, when multiplied by the original matrix, results in the identity matrix. The identity matrix is a special square matrix with ones on the main diagonal and zeros elsewhere.

	Not all matrices have an inverse. A square matrix has an inverse if and only if its determinant is nonzero. If a matrix does have an inverse, it is unique.

	The inverse of a matrix can be found using various methods, such as Gaussian elimination, the adjugate matrix, or the use of computer algorithms. The calculation of the inverse can be computationally expensive and may not be necessary in all applications, as sometimes the properties of the inverse can be used instead.

3. [E] What does the determinant of a matrix represent?
	
	*Answer:*
	The determinant of a matrix is a scalar value that summarizes certain properties of the matrix. It is calculated from the entries of a square matrix and is denoted by the symbol "det" or "| |".

	The determinant of a matrix has several important properties:

	It provides information about the linear transformation represented by the matrix: The determinant of a matrix represents the scaling factor of the transformation. If the determinant is zero, the transformation collapses all vectors to a lower dimension, and the matrix is said to be singular.

	It provides information about the orientation of the transformation: If the determinant of a matrix is positive, the orientation of the transformation is preserved, and if the determinant is negative, the orientation is reversed.

	It can be used in solving linear equations: The determinant of a matrix is used in Cramer's rule, which provides a solution to linear equations in terms of determinants.

	The calculation of the determinant can be done using various methods, such as the use of cofactors or the Laplace expansion. The determinant of a matrix is a fundamental concept in linear algebra, and it plays a crucial role in several areas of mathematics and science, including computer graphics, engineering, and physics.

4. [E] What happens to the determinant of a matrix if we multiply one of its rows by a scalar $$t \times R$$?
	
	*Answer:* The determinant of a matrix changes when you multiply one of its rows by a scalar. If you multiply one of the rows of a matrix by a scalar $t$, the determinant of the new matrix will be equal to $t$ times the determinant of the original matrix.
5. [M] A $$4 \times 4$$ matrix has four eigenvalues $$3, 3, 2, -1$$. What can we say about the trace and the determinant of this matrix?
	
	*Answer:* The trace of a matrix is equal to the sum of its eigenvalues, so in this case, the trace of the matrix is:

	$trace = 3 + 3 + 2 + (-1) = 7$.

	The determinant of a matrix is equal to the product of its eigenvalues, so in this case, the determinant of the matrix is:

	$det = 3 * 3 * 2 * (-1) = -18$.

	Therefore, we can conclude that the trace of the matrix is 7 and the determinant of the matrix is -18.
6. [M] Given the following matrix:<br>
	$$
	\begin{bmatrix}
		1 & 4 & -2 \\
		-1 & 3 & 2 \\
		3 & 5 & -6
	\end{bmatrix}
	$$

	Without explicitly using the equation for calculating determinants, what can we say about this matrix’s determinant?

	**Hint**: rely on a property of this matrix to determine its determinant.
	
	*Answer:* Using row manipulations $R1->R1+R2$, $R3->(R3+3R2)/2$, we have two equal rows, meaning determinant is 0. 
7. [M] What’s the difference between the covariance matrix $$AA^T$$ and the Gram matrix $$A^TA$$?
	
	*Answer:* Let A be normalised data matrix $D \times N$. 
	
	Covariance Matrix $\Sigma = AA^T$ is a $D \times D$ matrix who elements represents covariance of features. It's outer product.

	Gram Matrix $\Gamma= A^TA $ is a $N \times N$ matrix whose elements represent dot product of columns. It's inner product. 

	Ref: [PCA Lecture](https://courses.engr.illinois.edu/ece417/fa2017/ece417fa2017lecture7.pdf)
8. Given $$A \in R^{n \times m}$$ and $$b \in R^n$$
	1. [M] Find $$x$$ such that: $$Ax = b$$.
	
		*Answer:* One method to solve this system of equations is by using Gaussian elimination, which involves transforming the matrix $A$ into an upper triangular matrix, and then solving the resulting system of equations by back substitution.

		Ref: [Wiki](https://en.wikipedia.org/wiki/Gaussian_elimination)
	1. [E] When does this have a unique solution?
	
		*Answer:*  if and only if the matrix A has full rank.

	1. [M] Why is it when A has more columns than rows, $$Ax = b$$ has multiple solutions?
	
		*Answer:* When a matrix has more columns than rows, there are more variables than equations, meaning that not every column can have a pivot. This implies that the homogeneous problem has more variables than equations and thus has an infinite number of solutions

		Ref: [Quizlet](https://quizlet.com/606588513/linear-algebra-assignments-truefalse-flash-cards/), [Math 2270 -Lecture 16](https://www.math.utah.edu/~zwick/Classes/Fall2012_2270/Lectures/Lecture16_with_Examples.pdf)

	1. [M] Given a matrix A with no inverse. How would you solve the equation $$Ax = b$$? What is the pseudoinverse and how to calculate it?
	
		*Answer:*
		When the matrix A has no inverse, the equation $$Ax = b$$ may still have a solution, even if it is not unique. One approach to finding a solution in this case is to use the pseudoinverse of A, also known as the Moore-Penrose inverse. The pseudoinverse is calculated as $$A^+ = (A^TA)^{-1}A^T$$, and it provides the "best" solution in the least squares sense, meaning it minimizes the squared error between the approximation $$\hat{x} = A^+b$$ and the true value of x.

		pseudoinverse can be calculated using SVD.
		$$A^+ = VD^+U^T$$

		where:

		$A = U \Sigma V^T$ is the SVD of A, $D^+$ is the pseudoinverse of the diagonal matrix $\Sigma$, obtained by taking the reciprocal of the non-zero singular values and setting the rest to zero.
		$U$ and $V$ are unitary matrices, i.e., $U^TU = I$ and $V^TV = I$.

		Ref: [Stackexchange](https://math.stackexchange.com/questions/458404/how-can-we-compute-pseudoinverse-for-any-matrix)

9. Derivative is the backbone of gradient descent.
	1. [E] What does derivative represent?
	
		*Answer:* The derivative of a function at a certain point represents the rate of change of the function at that point.
	1. [M] What’s the difference between derivative, gradient, and Jacobian?
	
		*Answer:* The difference between derivative, gradient, and Jacobian are as follows:

		Derivative: a derivative of a function is the rate of change of the function at a particular point. It can be represented by a single number.

		Gradient: The gradient is the derivative of a scalar-valued function with respect to a vector. It represents the direction of maximum increase of the function.

		Jacobian: The Jacobian is the derivative of a vector-valued function with respect to a vector. It is a generalization of the gradient for functions that take more than one input.
10. [H] Say we have the weights $$w \in R^{d \times m}$$ and a mini-batch $$x$$ of $$n$$ elements, each element is of the shape $$1 \times d$$ so that $$x \in R^{n \times d}$$. We have the output $$y = f(x; w) = xw$$. What’s the dimension of the Jacobian $$\frac{\delta y}{\delta x}$$?
	
	*Answer:* The dimension of the Jacobian $\frac{\delta y}{\delta x}$ would be $ n \times d \times n \times m$.
11. [H] Given a very large symmetric matrix A that doesn’t fit in memory, say $$A \in R^{1M \times 1M}$$ and a function $$f$$ that can quickly compute $$f(x) = Ax$$ for $$x \in R^{1M}$$. Find the unit vector $$x$$ so that $$x^TAx$$ is minimal.
	
	**Hint**: Can you frame it as an optimization problem and use gradient descent to find an approximate solution?
	
	*Answer:*  Yes, the problem of finding the unit vector $x$ such that $x^TAx$ is minimal can be framed as an optimization problem and gradient descent can be used to find an approximate solution.

	The objective function is given by $f(x) = x^TAx$, which is the dot product of the vector $x$ with the matrix $A$, and is to be minimized. To use gradient descent, the gradient of the objective function must be calculated, which is given by $\nabla f(x) = 2Ax$. The optimization problem can then be solved iteratively by updating the unit vector $x$ in the direction of the negative gradient: $x_{k+1} = x_k - \alpha \nabla f(x_k)$, where $\alpha$ is the learning rate.

	To ensure that $x$ remains a unit vector, normalization can be applied after each iteration: $x_{k+1} = \frac{x_{k+1}}{\left|x_{k+1}\right|}$.

	This optimization process will converge to the desired solution, although it may take many iterations, depending on the choice of learning rate $\alpha$ and the initial value of $x$.
